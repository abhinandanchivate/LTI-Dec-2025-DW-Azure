
---

# âœ… Recommended Versions (IMPORTANT)

| Component             | Version               | Why                        |
| --------------------- | --------------------- | -------------------------- |
| **Python**            | **3.11.x**            | Fully supported by PySpark |
| **Java (JDK)**        | **Java 11**           | Spark 3.x compatible       |
| **PySpark**           | **3.5.x**             | Latest stable              |
| **Spark**             | **3.5.x (Pre-built)** | Matches PySpark            |
| **Hadoop (winutils)** | **3.3.x**             | For Windows HDFS support   |

> âŒ Python **3.13 is NOT supported** by PySpark yet
> âŒ Java 17/21 causes runtime issues

---

# 1ï¸âƒ£ Install Python 3.11 (Windows)

### ğŸ”¹ Download

ğŸ‘‰ [https://www.python.org/downloads/release/python-3119/](https://www.python.org/downloads/release/python-3119/)

### ğŸ”¹ Install (VERY IMPORTANT)

âœ” Check **â€œAdd Python to PATHâ€**
âœ” Install for **All Users**

### ğŸ”¹ Verify

```bat
python --version
pip --version
```

Expected:

```
Python 3.11.x
```

---

# 2ï¸âƒ£ Install Java JDK 11

### ğŸ”¹ Download (Eclipse Temurin â€“ Best)

ğŸ‘‰ [https://adoptium.net/temurin/releases/?version=11](https://adoptium.net/temurin/releases/?version=11)

Download:

* **JDK 11**
* **Windows x64**
* **MSI**

### ğŸ”¹ Install

Default path:

```
C:\Program Files\Eclipse Adoptium\jdk-11.x.x
```

### ğŸ”¹ Set JAVA_HOME

1. Open **System Environment Variables**
2. Add:

```
JAVA_HOME = C:\Program Files\Eclipse Adoptium\jdk-11.x.x
```

3. Update PATH:

```
%JAVA_HOME%\bin
```

### ğŸ”¹ Verify

```bat
java -version
```

Expected:

```
openjdk version "11"
```

---

# 3ï¸âƒ£ Install Apache Spark (Pre-built)

### ğŸ”¹ Download Spark

ğŸ‘‰ [https://spark.apache.org/downloads/](https://spark.apache.org/downloads/)

Select:

* Spark **3.5.x**
* Package type: **Pre-built for Apache Hadoop 3**
* Download `.zip`

### ğŸ”¹ Extract

```
C:\spark
```

Folder should contain:

```
C:\spark\bin
C:\spark\conf
C:\spark\jars
```

---

# 4ï¸âƒ£ Install Hadoop winutils (MANDATORY on Windows)

### ğŸ”¹ Download winutils

ğŸ‘‰ [https://github.com/cdarlint/winutils](https://github.com/cdarlint/winutils)

Download:

```
hadoop-3.3.x.zip
```

### ğŸ”¹ Extract

```
C:\hadoop
```

Ensure:

```
C:\hadoop\bin\winutils.exe
```

---

# 5ï¸âƒ£ Set Environment Variables (CRITICAL)

### ğŸ”¹ System Variables

| Variable       | Value                                          |
| -------------- | ---------------------------------------------- |
| JAVA_HOME      | `C:\Program Files\Eclipse Adoptium\jdk-11.x.x` |
| SPARK_HOME     | `C:\spark`                                     |
| HADOOP_HOME    | `C:\hadoop`                                    |
| PYSPARK_PYTHON | `python`                                       |

### ğŸ”¹ PATH (Add all)

```
%JAVA_HOME%\bin
%SPARK_HOME%\bin
%HADOOP_HOME%\bin
```

### ğŸ”¹ Restart PC (Mandatory)

---

# 6ï¸âƒ£ Install PySpark (Python Side)

```bat
pip install pyspark
```

Verify:

```bat
pip show pyspark
```

---

# 7ï¸âƒ£ Test PySpark (Terminal)

### ğŸ”¹ Python Test Script

Create `test_pyspark.py`

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("PySparkTest") \
    .master("local[*]") \
    .getOrCreate()

data = [("Abhi", 30), ("John", 25)]
df = spark.createDataFrame(data, ["Name", "Age"])
df.show()

spark.stop()
```

Run:

```bat
python test_pyspark.py
```

Expected Output:

```
+----+---+
|Name|Age|
+----+---+
|Abhi| 30|
|John| 25|
+----+---+
```

---

# 8ï¸âƒ£ Test Spark Shell

```bat
spark-shell
```

or PySpark shell:

```bat
pyspark
```

---

# 9ï¸âƒ£ Optional (VS Code Setup â€“ Recommended)

### ğŸ”¹ Install Extensions

* Python
* Pylance

### ğŸ”¹ Select Interpreter

```
Python 3.11.x
```

### ğŸ”¹ Run PySpark Scripts directly

---

# ğŸš¨ Common Errors & Fixes

### âŒ `Java gateway process exited`

âœ” Java version mismatch â†’ use **Java 11**

### âŒ `winutils.exe not found`

âœ” Ensure:

```
C:\hadoop\bin\winutils.exe
```

### âŒ `Python 3.13`

âœ” Downgrade to **3.11**

---

# ğŸ§  Best Practice (Training / Real Projects)

| Use Case           | Tool               |
| ------------------ | ------------------ |
| Exploration        | Jupyter Notebook   |
| Production scripts | VS Code            |
| Cluster learning   | WSL2 / Linux       |
| Big data labs      | Local Spark + HDFS |

---


